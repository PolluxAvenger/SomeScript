# coding=utf-8

import csv
import bs4
import sys
import time
import pickle
import random
import urllib.request

sys.setrecursionlimit(45000)


def marlware_data(result_list):
    header = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/46.0.2486.0 Safari/537.36 Edge/13.10586'
    }

    url = 'http://bgpranking.circl.lu'
    request = urllib.request.Request(url, headers=header)
    response = urllib.request.urlopen(request)
    content = response.read()
    result = bs4.BeautifulSoup(content, "html.parser")
    link = result.find_all('tr')
    count = 0

    for item in link:
        if count == 0:
            count += 1
            continue
        line_result = item.text.split('\n')
        result_list.append({'ASN' : line_result[1],
                             'Description' : line_result[2]})

    with open('bgp_malware.data', 'wb') as f:
        pickle.dump(result_list, f)

    return result_list


def extract():
    with open('bgp_malware.data', 'rb') as f:
        data_list = pickle.load(f)

    print('抽取完毕！共抽出' + str(len(data_list)) +'个数据行.')

    with open('bgp_malware.csv', 'w', newline='', encoding='utf-8') as t:
        headers = ['ASN', 'Description']
        writer = csv.DictWriter(t, headers)
        writer.writeheader()

        for item in data_list:
            writer.writerow(item)


if __name__ == "__main__":
    marlware_list = []
    marlware_list = marlware_data(marlware_list)
    print('一共有' + str(len(marlware_list)) + '条数据')
    extract()
